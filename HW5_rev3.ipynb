{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_rev3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fqim5DuIjgFC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goyetc/machine_translation/blob/master/HW5_rev3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKraYPnw4Vm5",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: English -> Spanish\n",
        "\n",
        "A minimal example based on the TensorFlow [tutorial](https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention) and this helpful [article](https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "552QcaE33U1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qXyJxYD593j",
        "colab_type": "code",
        "outputId": "0946538a-e9b6-47a4-dc2f-aa4805891c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install sacrebleu # https://github.com/mjpost/sacreBLEU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtYXP-576PSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import sacrebleu\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yv_IlLZevV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QafJn5Gh9Av",
        "colab_type": "code",
        "outputId": "49b09616-b498-4d0f-f31f-b82a74980fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fioYhbhhtpOi",
        "colab_type": "text"
      },
      "source": [
        "####Prep the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_9z6u8kiLlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('spa.txt','r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25b6RgQ1iTRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#eng = list()\n",
        "#spa = list()\n",
        "data = list()\n",
        "for line in file:\n",
        "  set = re.split(r'\\t+', line)\n",
        "  set[1] = set[1].rstrip()\n",
        "  data.append(set)\n",
        "  \n",
        "file.close()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuNLrnd7jTO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeYHPlcbkP0Y",
        "colab_type": "code",
        "outputId": "45670358-a0d7-4da1-d76c-fcf42b8ae11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhnxQDNco9iK",
        "colab_type": "code",
        "outputId": "bde3ec06-8486-4aa2-e799-8358fb9eb138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample = random.randint(0,len(data))\n",
        "data[sample]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There is no doubt about his ability.',\n",
              " 'No hay ninguna duda sobre su habilidad.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdl_R39MyUmb",
        "colab_type": "text"
      },
      "source": [
        "use this to test the model, then save it and move on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bg6mn6gwZwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_sample = random.sample(data,5000)\n",
        "train = data_sample[:4000]\n",
        "test = data_sample[4000:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2av9FTwyeos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run the test code through the model immediately after it finishes training. do not look at it. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyi0iK9NeCl6",
        "colab_type": "code",
        "outputId": "e92ed3e4-068d-469d-93e4-09ba9164fa0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train), len(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZMRazM5pijq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC4k6fgl6gEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(s):\n",
        "  # for details, see https://www.tensorflow.org/alpha/tutorials/sequences/nmt_with_attention\n",
        "  s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
        "  s = re.sub(r'[\" \"]+', \" \", s)\n",
        "  s = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", s)\n",
        "  s = s.strip()\n",
        "  s = '<start> ' + s + ' <end>'\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBKycWvF6hrG",
        "colab_type": "code",
        "outputId": "9c52c37c-9cf8-41c4-e61d-d52adbbaa38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Original:\", sentences[0])\n",
        "sentences = [(preprocess(source), preprocess(target)) for (source, target) in sentences]\n",
        "print(\"Preprocessed:\", sentences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: ['They were amazing.', 'Fueron maravillosos.']\n",
            "Preprocessed: ('<start> They were amazing . <end>', '<start> Fueron maravillosos . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRheDyz677X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_sentences, target_sentences = list(zip(*sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpUuxCmfGP-I",
        "colab_type": "code",
        "outputId": "51e5f285-501c-4cde-f64a-98d9054bb38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(target_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jK70lpkhaDz",
        "colab_type": "code",
        "outputId": "f1d39d58-e034-4b58-d5eb-bd4f7b1bf1e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(target_sentences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EigBfntVGRlT",
        "colab_type": "code",
        "outputId": "65c20178-7f14-47a3-91cf-4cbce8b1f54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(source_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvrGuXkkp1vN",
        "colab_type": "code",
        "outputId": "b863d420-60e1-4227-dd3d-35d11e81bf1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "source_sentences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> They were amazing . <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWbWYrUIAdxt",
        "colab_type": "code",
        "outputId": "7c6a82a0-546b-4085-a978-430a6a3ccb63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(source_sentences)\n",
        "source_data = source_tokenizer.texts_to_sequences(source_sentences)\n",
        "print(\"Sequence:\", source_data[0])\n",
        "source_data = tf.keras.preprocessing.sequence.pad_sequences(source_data, padding='post')\n",
        "print(\"Padded:\", source_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 48, 56, 1539, 3, 2]\n",
            "Padded: [   1   48   56 1539    3    2    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQtK0PavMtsd",
        "colab_type": "code",
        "outputId": "06d541ea-3aec-46f1-8987-496d586f39d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "source_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB8nZ8TUCGwU",
        "colab_type": "code",
        "outputId": "1b85dc9b-5470-46ac-8475-449315a25671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(target_sentences)\n",
        "target_data = target_tokenizer.texts_to_sequences(target_sentences)\n",
        "print(\"Sequence:\", target_data[0])\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, padding='post')\n",
        "print(\"Padded:\", target_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 316, 1779, 3, 2]\n",
            "Padded: [   1  316 1779    3    2    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBrHdodNGG-p",
        "colab_type": "code",
        "outputId": "19d0914e-bb79-44d2-9ee0-70e1f3ac8fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(target_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVZLYGOUM9yy",
        "colab_type": "code",
        "outputId": "34adab3e-99c8-43b6-f45b-fa7fcbc96140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhWMWEbe05Hb",
        "colab_type": "code",
        "outputId": "0dd20b5a-a736-4f14-afa4-4e753fbce961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels = np.zeros(target_data.shape)\n",
        "target_labels[:,0:target_data.shape[1] -1] = target_data[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data[0])\n",
        "print(\"Target label\", target_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [   1  316 1779    3    2    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "Target label [ 316. 1779.    3.    2.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8G7XznrGQY8",
        "colab_type": "code",
        "outputId": "d8ae8ac9-e339-4cb1-caa8-76e8f898077d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "source_vocab_size = len(source_tokenizer.word_index) + 1\n",
        "print(\"source vocab size: \" + str(source_vocab_size))\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "print(\"target vocab size: \" + str(target_vocab_size))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source vocab size: 3156\n",
            "target vocab size: 4467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3wj-l4hqd9q",
        "colab_type": "text"
      },
      "source": [
        "Interesting that the spanish vocabulary in this sample is ~50% larger than that of english"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RInhAa5juXma",
        "colab_type": "text"
      },
      "source": [
        "#### define functions..encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir6teLD0DVib",
        "colab_type": "code",
        "outputId": "e5bed73f-6cfd-4d92-8007-b838e0029299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def decode(encoded, tokenizer):\n",
        "  for number in encoded:\n",
        "    if number !=0:\n",
        "      print (\"%d -> %s\" % (number, tokenizer.index_word[number]))\n",
        "      \n",
        "decode(source_data[0], source_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "48 -> they\n",
            "56 -> were\n",
            "1539 -> amazing\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf5yfHccETFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 5\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_data, target_data, target_labels)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYNaoDqSFSrr",
        "colab_type": "code",
        "outputId": "b14a1f03-4db4-4da8-da5b-c63a30409c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_batch = next(iter(dataset))\n",
        "source, target, taget_labels = example_batch\n",
        "print(\"Shapes:\", source.shape, target.shape, taget_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (5, 28) (5, 27) (5, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6Ird0Elucli",
        "colab_type": "text"
      },
      "source": [
        "embedding size\n",
        "* chose an rnn with 64 units, and an embedding depth of 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqU008dQFd73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 32\n",
        "rnn_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9IBpuqAGAQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3UJBp40K2aq",
        "colab_type": "text"
      },
      "source": [
        "Demonstrate calling the encoder.\n",
        "* Note that I create a unique instance of encoder and decoder for part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMjL3nN2GBfw",
        "colab_type": "code",
        "outputId": "04eb20da-10c9-4c92-fc04-d74ab1965e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Create a batch of one sentence\n",
        "\n",
        "s = random.randint(0,len(sentences))\n",
        "\n",
        "ex_sentence = tf.expand_dims(source_data[s], axis=0)\n",
        "ex_translation = tf.expand_dims(target_data[s], axis=0)\n",
        "ex_labels = tf.expand_dims(target_labels[s], axis=0)\n",
        "print(ex_sentence.shape)\n",
        "\n",
        "encoder = Encoder()\n",
        "hidden_state = encoder.init_state(batch_size=1)\n",
        "print(hidden_state.shape)\n",
        "\n",
        "output, hidden_state = encoder(ex_sentence, hidden_state)\n",
        "print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28)\n",
            "(1, 64)\n",
            "(1, 28, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nONasBCIC6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUNFCk-ZVdgT",
        "colab_type": "text"
      },
      "source": [
        "Demonstrate calling the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCiY1TjLMZ1T",
        "colab_type": "code",
        "outputId": "4d21efaa-e286-4b79-a1ab-7a1b5b897977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = Decoder()\n",
        "decoder_output, decoder_state1 = decoder(ex_labels, hidden_state)\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 27, 4467)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhMLKqtkNA6p",
        "colab_type": "code",
        "outputId": "e264104c-4885-44db-adcc-289a76e83fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)\n",
        "\n",
        "print(\"Loss\", calc_loss(ex_labels, decoder_output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss tf.Tensor(1.8678355, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg7wRNgduwUE",
        "colab_type": "text"
      },
      "source": [
        "#### Translate function for part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9nYUsz3ZTGaZ",
        "colab": {}
      },
      "source": [
        "def translate_eng_to_esp(idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences))\n",
        "    \n",
        "    input_sent = source_data[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder(input_sent, hidden_state)\n",
        "    \n",
        "    decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder_output, decoder_state = decoder(decoder_input, decoder_state)\n",
        "        decoder_input = tf.argmax(decoder_output, -1)\n",
        "        word_idx = decoder_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences[idx][0], sentences[idx][1], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAR0qOfdWQWH",
        "colab_type": "code",
        "outputId": "2cfb381b-82ca-4e36-9d08-f4a0808378f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "input_sent, target_sent, translation = translate_eng_to_esp()\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> I did so at his request . <end>\n",
            "Target: <start> Yo lo hice a peticion suya . <end>\n",
            "Translation: quedaran malgastado escribire considerate sereno recordaron llamara fijare taxi diversiones propuesta adorable heroe llaves queria llegada tren sentados olvidado vive\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bcxlEtieSm9",
        "colab_type": "text"
      },
      "source": [
        "* gibberish, as expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NlQ-0CNu4oE",
        "colab_type": "text"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MUQX_Ltssut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEr-jDSpZ_Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step_1(source_seq, target_seq, target_labels, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder_output, encoder_state = encoder(source_seq, initial_state)\n",
        "    logits, decoder_state = decoder(target_seq, encoder_state)\n",
        "    loss = calc_loss(target_labels, logits)\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjIbuxscstrQ",
        "colab_type": "code",
        "outputId": "5446bd2b-fc1a-4ada-c4f2-b5b6044bf247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1737
        }
      },
      "source": [
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states = encoder.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels) in enumerate(dataset):\n",
        "      loss = train_step_1(source_seq, target_seq, target_labels, en_initial_states)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss, elapsed))\n",
        "      input_sent, target_sent, translation = translate_eng_to_esp()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.1651, Time 18.16 sec\n",
            "Input: <start> You don t have to get married if you don t want to . <end>\n",
            "Target: <start> No tenes que casarte si no queres . <end>\n",
            "Translation: ¿ no no no no la . <end>\n",
            "\n",
            "Epoch #10, Loss 0.7453, Time 14.05 sec\n",
            "Input: <start> Don t worry . He may look intimidating at first glance , but he s actually a very friendly person . <end>\n",
            "Target: <start> No temas , al principio puede parecer intimidante , pero el es realmente una persona muy amigable . <end>\n",
            "Translation: no me gusta una carta . <end>\n",
            "\n",
            "Epoch #20, Loss 0.5470, Time 7.27 sec\n",
            "Input: <start> What s that for ? <end>\n",
            "Target: <start> ¿ Para que vale eso ? <end>\n",
            "Translation: ¿ que te gusta el ? <end>\n",
            "\n",
            "Epoch #30, Loss 0.4423, Time 7.42 sec\n",
            "Input: <start> I ll drive to Boston . <end>\n",
            "Target: <start> Conducire hasta Boston . <end>\n",
            "Translation: yo renuncie a la estacion . <end>\n",
            "\n",
            "Epoch #40, Loss 0.3688, Time 7.18 sec\n",
            "Input: <start> It is necessary for you to go there . <end>\n",
            "Target: <start> Es necesario que vayas ahi . <end>\n",
            "Translation: es un callejon sin salida . <end>\n",
            "\n",
            "Epoch #50, Loss 0.2925, Time 7.87 sec\n",
            "Input: <start> If you listen to English programs on the radio , you can learn English for nothing . <end>\n",
            "Target: <start> Si escuchas programas en ingles en la radio puedes aprender ingles gratis . <end>\n",
            "Translation: si puedo das cerca para comprar algo , pero ella lo bese . <end>\n",
            "\n",
            "Epoch #60, Loss 0.2624, Time 7.94 sec\n",
            "Input: <start> I think you and Tom are more alike than you want to admit . <end>\n",
            "Target: <start> Yo pienso que tu y Tom son mas parecidos de lo que quieres admitir . <end>\n",
            "Translation: me gusta jugar al beisbol . <end>\n",
            "\n",
            "Epoch #70, Loss 0.2103, Time 7.22 sec\n",
            "Input: <start> I love rock musicians . <end>\n",
            "Target: <start> Adoro a los musicos de rock . <end>\n",
            "Translation: me gusta comer comida caliente y picante de vez en una semana . <end>\n",
            "\n",
            "Epoch #80, Loss 0.1535, Time 7.23 sec\n",
            "Input: <start> What s your favorite hotel in Boston ? <end>\n",
            "Target: <start> ¿ Cual es vuestro hotel favorito en Boston ? <end>\n",
            "Translation: ¿ que te nos ayude con tom ? <end>\n",
            "\n",
            "Epoch #90, Loss 0.1484, Time 7.17 sec\n",
            "Input: <start> I feel sad every now and then . <end>\n",
            "Target: <start> Me siento triste de vez en cuando . <end>\n",
            "Translation: me gusta ir a tocar la auto . <end>\n",
            "\n",
            "Epoch #100, Loss 0.1163, Time 7.18 sec\n",
            "Input: <start> There were two bridges . <end>\n",
            "Target: <start> Habia dos puentes . <end>\n",
            "Translation: habia dos puentes . <end>\n",
            "\n",
            "Epoch #110, Loss 0.1136, Time 7.22 sec\n",
            "Input: <start> Are you speaking to me ? <end>\n",
            "Target: <start> ¿ Estas hablando conmigo ? <end>\n",
            "Translation: ¿ podria venir ? <end>\n",
            "\n",
            "Epoch #120, Loss 0.0939, Time 7.21 sec\n",
            "Input: <start> Let s pretend it never happened . <end>\n",
            "Target: <start> Hagamos de cuenta que nunca paso . <end>\n",
            "Translation: hagamos de ver el libro . <end>\n",
            "\n",
            "Epoch #130, Loss 0.0848, Time 8.51 sec\n",
            "Input: <start> That ll last . <end>\n",
            "Target: <start> Durara . <end>\n",
            "Translation: durara . <end>\n",
            "\n",
            "Epoch #140, Loss 0.0987, Time 7.23 sec\n",
            "Input: <start> I will explain it to him . <end>\n",
            "Target: <start> Se lo explicare a el . <end>\n",
            "Translation: lo abofetee . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0577, Time 7.25 sec\n",
            "Input: <start> By this time next year , you will have visited almost all the famous places in Japan . <end>\n",
            "Target: <start> Por estas fechas del ano que viene , habras visitado casi todos los lugares famosos de Japon . <end>\n",
            "Translation: por favor , esperar por mi . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0673, Time 7.24 sec\n",
            "Input: <start> Don t be fooled again . <end>\n",
            "Target: <start> No te dejes enganar otra vez . <end>\n",
            "Translation: no te dejes enganar otra vez . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0549, Time 7.92 sec\n",
            "Input: <start> Do you really want to drive all night ? <end>\n",
            "Target: <start> ¿ De verdad quieres pasarte toda la noche conduciendo ? <end>\n",
            "Translation: ¿ de verdad quieres pasarte toda la noche ? <end>\n",
            "\n",
            "Epoch #180, Loss 0.0572, Time 8.16 sec\n",
            "Input: <start> Stop saying that . <end>\n",
            "Target: <start> Dejen de decir eso . <end>\n",
            "Translation: dejen de copuchar . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0381, Time 7.15 sec\n",
            "Input: <start> His family didn t have much money . <end>\n",
            "Target: <start> Su familia no tenia mucho dinero . <end>\n",
            "Translation: su familia no tenia una tarta para la primera , ya estaba aqui en el mundo . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnu4Vt90E90",
        "colab_type": "text"
      },
      "source": [
        "Loss < 0.10 after 100 epochs, looks pretty good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCcINZXR1q-b",
        "colab_type": "text"
      },
      "source": [
        "But clearly still some funny quirks, a la epoch 130:\n",
        "* Input: <start> I like English , too . <end>\n",
        "* Target: <start> A mi tambien me gusta el ingles . <end>\n",
        "* Translation: me gusta jugar al beisbol . <end>\n",
        "  \n",
        "Which translates to.. \"I like to play baseball\". The english prefer cricket.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRmzgOEs3ejv",
        "colab_type": "text"
      },
      "source": [
        "Loss appears to flatten out around 150 epochs (more like 200), and we're likely overfitting to the sample set after this point. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQKaLOyY9TDE",
        "colab_type": "text"
      },
      "source": [
        "Calculate BLEU Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdtKNYAteykd",
        "colab_type": "code",
        "outputId": "5924be53-893c-4257-c805-252b2f5f2b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "original1, references1, hypotheses1 = [], [], []\n",
        "\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "#for i in range(10):\n",
        "  input_sent, target_sent, translation = translate_eng_to_esp()\n",
        "  original1.append(input_sent)\n",
        "  references1.append(target_sent)\n",
        "  hypotheses1.append(\"<start> \" + translation)\n",
        "  \n",
        "results1 = sacrebleu.raw_corpus_bleu(hypotheses1, [references1])\n",
        "print(results1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=20.61060634910397, counts=[18554, 8683, 3912, 2928], totals=[38115, 34115, 30115, 26115], precisions=[48.678997769906864, 25.452147149347795, 12.990204217167525, 11.211947156806433], bp=1.0, sys_len=38115, ref_len=36978)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuUPzE0uROmL",
        "colab_type": "text"
      },
      "source": [
        "despite minimal loss, I achieved BLEU scores of 50 or below on multiple runs.. \n",
        "* except one, where I achieved 60:\n",
        "* BLEU(score=59.856526611808704, counts=[30867, 21448, 16608, 12947], totals=[38537, 34537, 30537, 26537], precisions=[80.09704958870695, 62.10151431797782, 54.38648197268887, 48.788484003466856], bp=0.9930697700178548, sys_len=38537, ref_len=38805)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiBMJYqy6WLU",
        "colab_type": "text"
      },
      "source": [
        "translate a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5BYUZyDBxA1J",
        "colab": {}
      },
      "source": [
        "input_sent1, target_sent1, translation1 = translate_eng_to_esp(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM2j28LGxGrC",
        "colab_type": "code",
        "outputId": "c7eabb5f-d457-49e9-9a6a-a09dfa3fca0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent1, target_sent1, translation1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> I don t think there s anything in the box . <end>\n",
            "Target: <start> No creo que haya nada en la caja . <end>\n",
            "Translation: no creo que haya nada en la caja . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt9rt6388ime",
        "colab_type": "text"
      },
      "source": [
        "#Part 2: Spanish -> English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "097ba95e-6e8e-4efe-e869-92ae9e17ff15",
        "id": "QbxWwR9RYcl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['They were amazing.', 'Fueron maravillosos.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P1Y2oArqYcl_",
        "colab": {}
      },
      "source": [
        "sentences_swapped = [(t[1], t[0]) for t in train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5baa6a90-f02f-479c-84be-93a748ee755c",
        "id": "bcbqqoc0YcmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences_swapped[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Fueron maravillosos.', 'They were amazing.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "16ce28dd-2fa0-4a5e-9c82-5d60d026321d",
        "id": "HRqyMChYYcmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Original:\", sentences_swapped[0])\n",
        "sentences_swapped = [(preprocess(source), preprocess(target)) for (source, target) in sentences_swapped]\n",
        "print(\"Preprocessed:\", sentences_swapped[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: ('Fueron maravillosos.', 'They were amazing.')\n",
            "Preprocessed: ('<start> Fueron maravillosos . <end>', '<start> They were amazing . <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "isuNiptlYcmL",
        "colab": {}
      },
      "source": [
        "source_sentences2, target_sentences2 = list(zip(*sentences_swapped))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "de2e10ea-1a09-458b-c6c7-e49d7c9b3eab",
        "id": "oBKq6W7eYcmN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "source_sentences2[0], target_sentences2[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> Fueron maravillosos . <end>', '<start> They were amazing . <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN6G4r-eZJ8N",
        "colab_type": "code",
        "outputId": "c218e2d1-f51d-4a8e-c6c8-8ebfbe6a5df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "hypotheses1[0], original1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<start> estoy ansioso por escuchar lo que piensas de este asunto . <end>',\n",
              " '<start> I m sure Tom will succeed . <end>')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqim5DuIjgFC",
        "colab_type": "text"
      },
      "source": [
        "### process data for second model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "760bd5b2-8ff9-4c7c-d5ea-19ae63d7106e",
        "id": "BbiTSgtgYcmR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "source_tokenizer2 = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer2.fit_on_texts(source_sentences2)\n",
        "source_data2 = source_tokenizer2.texts_to_sequences(source_sentences2)\n",
        "print(\"Sequence:\", source_data2[0])\n",
        "source_data2 = tf.keras.preprocessing.sequence.pad_sequences(source_data2, padding='post')\n",
        "print(\"Padded:\", source_data2[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 316, 1779, 3, 2]\n",
            "Padded: [   1  316 1779    3    2    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "774354af-dd1f-4924-f21f-d29d180df9bf",
        "id": "68wpV9PLYcmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "target_tokenizer2 = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer2.fit_on_texts(target_sentences2)\n",
        "target_data2 = target_tokenizer2.texts_to_sequences(target_sentences2)\n",
        "print(\"Sequence:\", target_data2[0])\n",
        "target_data2 = tf.keras.preprocessing.sequence.pad_sequences(target_data2, padding='post')\n",
        "print(\"Padded:\", target_data2[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 48, 56, 1539, 3, 2]\n",
            "Padded: [   1   48   56 1539    3    2    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0a663321-4063-4d54-c2d8-6af2c2d47537",
        "id": "nTbmN3A_Ycme",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels2 = np.zeros(target_data2.shape)\n",
        "target_labels2[:,0:target_data2.shape[1] -1] = target_data2[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data2[0])\n",
        "print(\"Target label\", target_labels2[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [   1   48   56 1539    3    2    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "Target label [  48.   56. 1539.    3.    2.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "    0.    0.    0.    0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9ab9cacb-3849-4ade-8904-63de7a9b32f0",
        "id": "k8iBSILRYcmi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "source_vocab_size2 = len(source_tokenizer2.word_index) + 1\n",
        "print(\"source vocab size: \" + str(source_vocab_size2))\n",
        "target_vocab_size2 = len(target_tokenizer2.word_index) + 1\n",
        "print(\"target vocab size: \" + str(target_vocab_size2))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source vocab size: 4467\n",
            "target vocab size: 3156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vV7WeQvEYcmk"
      },
      "source": [
        "Note that here, we have a compressed vocab size from source to target. Suspect this might produce higher loss, but actually a better BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "611c3703-bdb6-4a2e-e1eb-6a81b25f48c8",
        "id": "LaTegJ5dYcmk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "decode(source_data2[0], source_tokenizer2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "316 -> fueron\n",
            "1779 -> maravillosos\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_BVKGW2UYcmn",
        "colab": {}
      },
      "source": [
        "#batch_size = 5\n",
        "dataset2 = tf.data.Dataset.from_tensor_slices((source_data2, target_data2, target_labels2)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6584b202-99be-47ed-8e62-80c1b689a3c9",
        "id": "VAC1ZJRnYcmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_batch2 = next(iter(dataset2))\n",
        "source2, target2, taget_labels2 = example_batch2\n",
        "print(\"Shapes:\", source2.shape, target2.shape, taget_labels2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes: (5, 27) (5, 28) (5, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SDIhjQcOYcms",
        "colab": {}
      },
      "source": [
        "#same as before\n",
        "#embedding_size = 32\n",
        "#rnn_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ugIdPloMYcmt",
        "colab": {}
      },
      "source": [
        "class Encoder2(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder2, self).__init__()\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(source_vocab_size2,\n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    \n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)        \n",
        "    return output, state\n",
        "  \n",
        "  def init_state(self, batch_size):\n",
        "    return tf.zeros((batch_size, rnn_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "87LYphZVYcmv"
      },
      "source": [
        "Demonstrate calling the encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "717bbc12-8fc9-431d-d430-689b3f8effc1",
        "id": "5m_X3zEjYcmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Create a batch of one sentence\n",
        "\n",
        "s2 = random.randint(0,len(sentences_swapped))\n",
        "\n",
        "ex_sentence2 = tf.expand_dims(source_data2[s], axis=0)\n",
        "ex_translation2 = tf.expand_dims(target_data2[s], axis=0)\n",
        "ex_labels2 = tf.expand_dims(target_labels2[s], axis=0)\n",
        "print(ex_sentence2.shape)\n",
        "\n",
        "encoder2 = Encoder2()\n",
        "hidden_state2 = encoder2.init_state(batch_size=1)\n",
        "print(hidden_state2.shape)\n",
        "\n",
        "output2, hidden_state2 = encoder2(ex_sentence2, hidden_state2)\n",
        "print(output2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 27)\n",
            "(1, 64)\n",
            "(1, 27, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z3hzVwwmYcm1",
        "colab": {}
      },
      "source": [
        "class Decoder2(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder2, self).__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size2, \n",
        "                                               embedding_size)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_size, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(target_vocab_size2)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    logits = self.dense(output)\n",
        "    return logits, state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6SKijTM0Ycm2"
      },
      "source": [
        "Demonstrate calling the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "11517c9f-8ade-4e42-e65b-f3becc2651fa",
        "id": "DOmwwBNCYcm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder2 = Decoder2()\n",
        "decoder2_output, decoder2_state = decoder2(ex_labels2, hidden_state2)\n",
        "print(decoder2_output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 3156)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3699cf2f-f4af-4fcb-c60c-8e88e566e258",
        "id": "HtWxyDUrYcm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "'''def calc_loss(targets, logits):\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  mask = tf.cast(mask, dtype=tf.int64)\n",
        "  return crossentropy(targets, logits, sample_weight=mask)'''\n",
        "\n",
        "print(\"Loss\", calc_loss(ex_labels2, decoder2_output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss tf.Tensor(1.4386643, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2QrIMCYdHBw",
        "colab_type": "text"
      },
      "source": [
        "### Esp to eng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vIo1avrXYcm6",
        "colab": {}
      },
      "source": [
        "def translate_esp_to_eng(idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(sentences_swapped))\n",
        "    \n",
        "    input_sent = source_data2[idx]\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder2.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder2(input_sent, hidden_state)\n",
        "    \n",
        "    decoder2_input = tf.expand_dims([target_tokenizer2.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder2_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder2_output, decoder2_state = decoder2(decoder2_input, decoder2_state)\n",
        "        decoder2_input = tf.argmax(decoder2_output, -1)\n",
        "        word_idx = decoder2_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer2.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return sentences_swapped[idx][0], sentences_swapped[idx][1], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "18928b46-a1f2-451c-b413-3fda8e13f346",
        "id": "IQLKxYsfYcm7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "input_sent, target_sent, translation = translate_esp_to_eng()\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> No puedo ayudar a Tom con su tarea . <end>\n",
            "Target: <start> I can t help Tom with his homework . <end>\n",
            "Translation: five take aboard hawaii stairs ears chose bitten unlocked proper awful anyone sleeping cousin awful guarantee programs visit blaming chose\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x58yYD-TOuJk",
        "colab_type": "text"
      },
      "source": [
        "gibberish here again, as expected prior to training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4gKUMSzYcm8",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MV86sUhjYcm9",
        "colab": {}
      },
      "source": [
        "@tf.function # remove this annotation when debugging\n",
        "def train_step_2(source_seq, target_seq, target_labels2, initial_state):\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    encoder2_output, encoder2_state = encoder2(source_seq, initial_state)\n",
        "    logits, decoder2_state = decoder2(target_seq, encoder2_state)\n",
        "    loss = calc_loss(target_labels2, logits)\n",
        "\n",
        "  variables = encoder2.trainable_variables + decoder2.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sFtPmJXRYcm_"
      },
      "source": [
        "200 Epochs were initially used as I observed overfitting in part 1 near this #, but I found 200 epochs to produce inferior results for a re-do of english -> spanish. \n",
        "* Sticking with 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d70513b0-a27f-46d1-f290-d7436bf01c74",
        "id": "Wn-6mTcuYcnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "EPOCHS = 200\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "  \n",
        "    en_initial_states2 = encoder2.init_state(batch_size)\n",
        "    \n",
        "    for batch, (source_seq, target_seq, target_labels2) in enumerate(dataset2):\n",
        "      loss2 = train_step_2(source_seq, target_seq, target_labels2, en_initial_states2)\n",
        "      elapsed = time.time() - start\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(\"Epoch #%d, Loss %.4f, Time %.2f sec\" % (epoch, loss2, elapsed))\n",
        "      input_sent, target_sent, translation = translate_esp_to_eng()\n",
        "      print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent, target_sent, translation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0, Loss 1.0993, Time 9.20 sec\n",
            "Input: <start> Tom mando a Mary a casa . <end>\n",
            "Target: <start> Tom sent Mary home . <end>\n",
            "Translation: i is to the lot . <end>\n",
            "\n",
            "Epoch #10, Loss 0.6501, Time 7.25 sec\n",
            "Input: <start> He estado leyendo este libro . <end>\n",
            "Target: <start> I have been reading this book . <end>\n",
            "Translation: i don t know what you want to be here . <end>\n",
            "\n",
            "Epoch #20, Loss 0.4849, Time 7.23 sec\n",
            "Input: <start> Me dormi escuchando la radio . <end>\n",
            "Target: <start> I fell asleep while listening to the radio . <end>\n",
            "Translation: i didn t know if you were . <end>\n",
            "\n",
            "Epoch #30, Loss 0.3511, Time 7.24 sec\n",
            "Input: <start> Quieto . <end>\n",
            "Target: <start> Stay still . <end>\n",
            "Translation: leave your house . <end>\n",
            "\n",
            "Epoch #40, Loss 0.2692, Time 7.24 sec\n",
            "Input: <start> Fueron al festival de musica . <end>\n",
            "Target: <start> They went to the music festival . <end>\n",
            "Translation: they went to school . <end>\n",
            "\n",
            "Epoch #50, Loss 0.2288, Time 7.28 sec\n",
            "Input: <start> El esta con otro telefono . <end>\n",
            "Target: <start> He is on another phone . <end>\n",
            "Translation: he is a mathematical genius . <end>\n",
            "\n",
            "Epoch #60, Loss 0.1784, Time 7.25 sec\n",
            "Input: <start> Bueno , ¿ que quieres que diga ? <end>\n",
            "Target: <start> Well , what do you want me to say ? <end>\n",
            "Translation: well , tom thought he didn t want to . <end>\n",
            "\n",
            "Epoch #70, Loss 0.1784, Time 7.52 sec\n",
            "Input: <start> Se lo explicare a el . <end>\n",
            "Target: <start> I will explain it to him . <end>\n",
            "Translation: i will explain it to the doctor . <end>\n",
            "\n",
            "Epoch #80, Loss 0.1288, Time 8.36 sec\n",
            "Input: <start> Si ella conociera tu direccion , te escribiria . <end>\n",
            "Target: <start> If she knew your address , she would write to you . <end>\n",
            "Translation: if she knew it about your television ? <end>\n",
            "\n",
            "Epoch #90, Loss 0.1231, Time 7.71 sec\n",
            "Input: <start> Hay algo ahi . <end>\n",
            "Target: <start> There s something there . <end>\n",
            "Translation: there s no problem . <end>\n",
            "\n",
            "Epoch #100, Loss 0.1024, Time 7.26 sec\n",
            "Input: <start> Tengo que ser sincero estaba un poco nervioso la primera vez que me hicieron una resonancia . <end>\n",
            "Target: <start> I have to be honest . I was a little bit nervous the first time I had an MRI scan . <end>\n",
            "Translation: i have to be honest . i come back at this . <end>\n",
            "\n",
            "Epoch #110, Loss 0.0972, Time 7.30 sec\n",
            "Input: <start> ¿ Cual es vuestro problema ? <end>\n",
            "Target: <start> What is your problem ? <end>\n",
            "Translation: what s your shoe size ? <end>\n",
            "\n",
            "Epoch #120, Loss 0.0954, Time 7.30 sec\n",
            "Input: <start> ¿ Hay una farmacia cerca ? <end>\n",
            "Target: <start> Is there a pharmacy nearby ? <end>\n",
            "Translation: is there a pharmacy nearby ? <end>\n",
            "\n",
            "Epoch #130, Loss 0.0723, Time 7.33 sec\n",
            "Input: <start> ¿ Que pasa ? <end>\n",
            "Target: <start> What s the matter ? <end>\n",
            "Translation: what s the matter ? <end>\n",
            "\n",
            "Epoch #140, Loss 0.0585, Time 7.23 sec\n",
            "Input: <start> Lei su libro . <end>\n",
            "Target: <start> I read his book . <end>\n",
            "Translation: i read his book . <end>\n",
            "\n",
            "Epoch #150, Loss 0.0486, Time 7.22 sec\n",
            "Input: <start> Me sentia solo . <end>\n",
            "Target: <start> I felt alone . <end>\n",
            "Translation: i felt alone . <end>\n",
            "\n",
            "Epoch #160, Loss 0.0420, Time 7.34 sec\n",
            "Input: <start> Su belleza se ajara con el tiempo . <end>\n",
            "Target: <start> Her beauty will fade in time . <end>\n",
            "Translation: her beauty will fade in time . <end>\n",
            "\n",
            "Epoch #170, Loss 0.0337, Time 7.27 sec\n",
            "Input: <start> Me suena a chino . <end>\n",
            "Target: <start> It s Greek to me . <end>\n",
            "Translation: it s greek to me . <end>\n",
            "\n",
            "Epoch #180, Loss 0.0428, Time 7.62 sec\n",
            "Input: <start> Deberias pagarlo . <end>\n",
            "Target: <start> You should pay for it . <end>\n",
            "Translation: you should pay for it . <end>\n",
            "\n",
            "Epoch #190, Loss 0.0245, Time 7.28 sec\n",
            "Input: <start> Es el cuadro que pinto Mary . <end>\n",
            "Target: <start> This is the picture that Mary painted . <end>\n",
            "Translation: this is the picture that mary painted . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkcHh_6kYLQ3",
        "colab_type": "text"
      },
      "source": [
        "swap source and target location to preserve rest of script\n",
        "* Note that the same dataset was used as part 1 for a controlled comparison of performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yI4vtrNJFHXU"
      },
      "source": [
        "Loss is higher than the equivalent english -> spanish results, using the same sample of data.\n",
        "* Wonder if this has to do with the 'compressed' vocab size of english vs spanish. \n",
        "* Still, results look good, and the BLEU score is not significantly different\n",
        "* In fact, the BLEU score is higher for the Spanish -> English translation, despite greater loss\n",
        "* - again, this may have to do with a smaller vocabulary in the English language portion of the sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wspIt51-8j6P"
      },
      "source": [
        "Calculate BLEU Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hhJNRy4XFHXV",
        "outputId": "384fc170-1dec-4a3b-cd04-a2f5b3bfddeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "references2, hypotheses2 = [], []\n",
        "\n",
        "\n",
        "for i in range(len(sentences_swapped)):\n",
        "  input_sent, target_sent, translation = translate_esp_to_eng()\n",
        "  references2.append(target_sent)\n",
        "  hypotheses2.append(\"<start> \" + translation)\n",
        "  \n",
        "results2 = sacrebleu.raw_corpus_bleu(hypotheses2, [references2])\n",
        "print(results2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=56.27093543007827, counts=[29793, 20184, 15353, 11890], totals=[38657, 34657, 30657, 26657], precisions=[77.07012960136586, 58.23931673255042, 50.07991649541703, 44.603668829950855], bp=1.0, sys_len=38657, ref_len=38442)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4dpAwEHXjWQ",
        "colab_type": "text"
      },
      "source": [
        "the bleu score is consistently higher for spanish to english, despite higher loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFFrW3nPHZnc",
        "colab": {}
      },
      "source": [
        "input_sent2, target_sent2, translation2 = translate_esp_to_eng(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6_8uAPLmHZnf",
        "outputId": "9e83927f-084a-479a-b84f-8e045e3c2317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent2, target_sent2, translation2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> No creo que haya nada en la caja . <end>\n",
            "Target: <start> I don t think there s anything in the box . <end>\n",
            "Translation: i don t think there s anything in so those went shopping elsewhere . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QGe_jrV4Xs_b",
        "colab": {}
      },
      "source": [
        "input_sent2, target_sent2, translation2 = translate_esp_to_eng(random.randint(0,len(test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a18fb167-feea-4e4f-d33e-804c912b3096",
        "id": "4Hb0dvJmXs_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent2, target_sent2, translation2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> Ella es buena esquiando . <end>\n",
            "Target: <start> She is good at skiing . <end>\n",
            "Translation: she is good at skiing . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M0hAKMKekyP",
        "colab_type": "text"
      },
      "source": [
        "# Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFbfFuwGJREb",
        "colab_type": "text"
      },
      "source": [
        "## Part 3\n",
        "* Use test set from beginning -  created true/unobserved test set by pulling a random sample of 5000 sets and then partitioning that sample into train and test sets\n",
        "* We will extract the translations after the first english -> spanish training steps, and then use those translations as the source for a spanish to english translation. \n",
        "* The tokenizations will also be used from the second model, as we are treating the translated words from the original model in part 1 as the ground trouth in part 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_uuEYtbXzxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test)):\n",
        "  input_sent, target_sent, translation = translate_esp_to_eng(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLE4pgTYYgdv",
        "colab_type": "code",
        "outputId": "3ca3172d-2b18-459f-8fa1-55943ab6894c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "hypotheses1[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> estoy ansioso por escuchar lo que piensas de este asunto . <end>',\n",
              " '<start> el alcanzare pronto . <end>',\n",
              " '<start> parece estar muy de clase . <end>',\n",
              " '<start> ¿ no lo mas este de cinco ? <end>',\n",
              " '<start> ya tienes edad para mantenerte solo . <end>',\n",
              " '<start> se durmio en clase de historia . <end>',\n",
              " '<start> ¿ cual es tu talla de correos he estado fumando tomar ? <end>',\n",
              " '<start> no quiero esperar hoy . <end>',\n",
              " '<start> una mirada contenta aparecio en su rostro . <end>',\n",
              " '<start> que me gustaria estar bien con mi . <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjbkAaqIYvsq",
        "colab_type": "code",
        "outputId": "a004edb9-110e-4bac-81c1-5a7d5edbe0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "original1[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> I m sure Tom will succeed . <end>',\n",
              " '<start> You were lucky . <end>',\n",
              " '<start> He seems quite happy . <end>',\n",
              " '<start> Don t you think this computer game may be a little too difficult for Tom ? <end>',\n",
              " '<start> You are now old enough to support yourself . <end>',\n",
              " '<start> I know that would make me happy . <end>',\n",
              " '<start> What did you buy her for Christmas ? <end>',\n",
              " '<start> I don t want any distractions . <end>',\n",
              " '<start> A look of contentment appeared on his face . <end>',\n",
              " '<start> She was poor , but she was honest . <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzgOoqrY6Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4b69eae4-b726-443c-e3d7-dd423489324a",
        "id": "TUa9SVHAZhgd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "source_data3 = source_tokenizer2.texts_to_sequences(hypotheses1)\n",
        "print(\"Sequence:\", source_data3[9])\n",
        "source_data3 = tf.keras.preprocessing.sequence.pad_sequences(source_data3, padding='post')\n",
        "print(\"Padded:\", source_data3[9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 4, 17, 171, 130, 115, 26, 24, 3, 2]\n",
            "Padded: [  1   4  17 171 130 115  26  24   3   2   0   0   0   0   0   0   0   0\n",
            "   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bfa1dc1a-9b60-4fd0-f44b-72bb08442cd2",
        "id": "z637LseVZhgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "target_data3 = target_tokenizer2.texts_to_sequences(original1)\n",
        "print(\"Sequence:\", target_data3[9])\n",
        "target_data3 = tf.keras.preprocessing.sequence.pad_sequences(target_data3, padding='post')\n",
        "print(\"Padded:\", target_data3[9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: [1, 26, 21, 980, 19, 88, 26, 21, 703, 3, 2]\n",
            "Padded: [  1  26  21 980  19  88  26  21 703   3   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6989b4f7-b55b-470f-a97d-42a7cb17729c",
        "id": "WCxT4V_fZhgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Create labels for the decoder by shifting the target sequence\n",
        "# one to the right.\n",
        "target_labels3 = np.zeros(target_data3.shape)\n",
        "target_labels3[:,0:target_data3.shape[1] -1] = target_data3[:,1:]\n",
        "\n",
        "print(\"Target sequence\", target_data3[0])\n",
        "print(\"Target label\", target_labels3[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target sequence [  1   4  46 215   8  60 754   3   2   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0]\n",
            "Target label [  4.  46. 215.   8.  60. 754.   3.   2.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4856ae38-4343-43ad-9a58-28f9a4570883",
        "id": "Vb7xwxRFZhgo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "source_vocab_size3 = len(source_tokenizer2.word_index) + 1\n",
        "print(\"source vocab size: \" + str(source_vocab_size3))\n",
        "target_vocab_size3 = len(target_tokenizer2.word_index) + 1\n",
        "print(\"target vocab size: \" + str(target_vocab_size3))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source vocab size: 4467\n",
            "target vocab size: 3156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtcZjjtJf3uJ",
        "colab_type": "code",
        "outputId": "652b1e1c-06b6-4e6b-d54b-d4e3cb62a0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hypotheses1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> estoy ansioso por escuchar lo que piensas de este asunto . <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxS7Dpb2fgtg",
        "colab_type": "code",
        "outputId": "3525643b-0d39-46aa-acc5-8339d85d429f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "decode(source_data3[0], source_tokenizer2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "51 -> estoy\n",
            "4360 -> ansioso\n",
            "22 -> por\n",
            "1012 -> escuchar\n",
            "21 -> lo\n",
            "4 -> que\n",
            "345 -> piensas\n",
            "5 -> de\n",
            "39 -> este\n",
            "328 -> asunto\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpaU1MLUf8eG",
        "colab_type": "code",
        "outputId": "087aa826-e8aa-4bc3-eabe-282c3ce5c5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "original1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> I m sure Tom will succeed . <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W1s0ySJfoip",
        "colab_type": "code",
        "outputId": "63e847d6-682a-4d5f-d777-406374425b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "decode(target_data3[0], target_tokenizer2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "4 -> i\n",
            "46 -> m\n",
            "215 -> sure\n",
            "8 -> tom\n",
            "60 -> will\n",
            "754 -> succeed\n",
            "3 -> .\n",
            "2 -> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fK2luEXFbCXW",
        "colab": {}
      },
      "source": [
        "#batch_size = 5\n",
        "dataset3 = tf.data.Dataset.from_tensor_slices((source_data3, target_data3, target_labels3)).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fg1MMjH4dOBD",
        "colab": {}
      },
      "source": [
        "def translate_esp_to_eng_2(idx=None):\n",
        "  \n",
        "    if idx == None: \n",
        "      idx = np.random.choice(len(test))\n",
        "    \n",
        "    input_sent = source_data3[idx]\n",
        "    #decode(input_sent, source_tokenizer2)\n",
        "    input_sent = tf.expand_dims(input_sent, axis=0)\n",
        "    \n",
        "    hidden_state = encoder2.init_state(batch_size=1)\n",
        "    output, hidden_state = encoder2(input_sent, hidden_state)\n",
        "    \n",
        "    decoder2_input = tf.expand_dims([target_tokenizer2.word_index['<start>']], 0)\n",
        "    out_words = []\n",
        "    \n",
        "    decoder2_state = hidden_state\n",
        "\n",
        "    while True:\n",
        "      \n",
        "        decoder2_output, decoder2_state = decoder2(decoder2_input, decoder2_state)\n",
        "        decoder2_input = tf.argmax(decoder2_output, -1)\n",
        "        word_idx = decoder2_input.numpy()[0][0]\n",
        "        # if we've predicted 0 (which is reserved, usually this will only happen\n",
        "        # before the decoder is trained, just stop translating and return\n",
        "        # what we have)\n",
        "        if word_idx == 0: \n",
        "          out_words.append('<end>')\n",
        "        else:\n",
        "          out_words.append(target_tokenizer2.index_word[word_idx])\n",
        "\n",
        "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
        "          break\n",
        "          \n",
        "    translation = ' '.join(out_words)    \n",
        "    return hypotheses1[idx], original1[idx], translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmATL0T6cjwS",
        "colab_type": "code",
        "outputId": "d6564b32-d62a-4565-b0b0-4674332afe99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "input_sent_test, target_sent_test, translation_test = translate_esp_to_eng_2(9)\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent_test, target_sent_test, translation_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> <start>\n",
            "4 -> que\n",
            "17 -> me\n",
            "171 -> gustaria\n",
            "130 -> estar\n",
            "115 -> bien\n",
            "26 -> con\n",
            "24 -> mi\n",
            "3 -> .\n",
            "2 -> <end>\n",
            "Input: <start> que me gustaria estar bien con mi . <end>\n",
            "Target: <start> She was poor , but she was honest . <end>\n",
            "Translation: i d like you to attend something ? <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsL_PcFeDHa",
        "colab_type": "code",
        "outputId": "7e70a506-e678-44a7-e3a6-8d6fa588f1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "references3, hypotheses3 = [], []\n",
        "  \n",
        "for i in range(len(test)):\n",
        "  input_sent, target_sent, translation = translate_esp_to_eng_2(i)\n",
        "  references3.append(target_sent)\n",
        "  hypotheses3.append(\"<start> \" + translation)\n",
        "  \n",
        "results3 = sacrebleu.raw_corpus_bleu(hypotheses3, [references3])\n",
        "print(results3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU(score=19.511622655125215, counts=[4533, 2028, 967, 750], totals=[9749, 8749, 7749, 6749], precisions=[46.49707662324341, 23.179791976225854, 12.479029552200284, 11.112757445547489], bp=0.9923364194021157, sys_len=9749, ref_len=9824)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7RJZILjFM6",
        "colab_type": "text"
      },
      "source": [
        "Bleu score not great.. 19.5 vs ~60 for the original ground truth spanish examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lj74zTwjMs8",
        "colab_type": "code",
        "outputId": "6bac8f40-a6cd-49b3-9f31-11080c583769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "input_sent_test, target_sent_test, translation_test = translate_esp_to_eng_2(8)\n",
        "print(\"Input: %s\\nTarget: %s\\nTranslation: %s\\n\" % (input_sent_test, target_sent_test, translation_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> una mirada contenta aparecio en su rostro . <end>\n",
            "Target: <start> A look of contentment appeared on his face . <end>\n",
            "Translation: a look of contentment appeared on his face . <end>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AK4Wk_zka8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}